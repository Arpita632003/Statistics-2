{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfd68ac-a250-4d92-94e0-9278eb3776be",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is hypothesis testing in statistics\n",
    "Hypothesis testing is a statistical method that is used to make a statistical decision using experimental data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee888921-9fad-4c20-8b03-9e2e12d52f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123bf132-d063-484e-b7f0-3ca6f683df21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b3fd65-f78b-47c7-be07-99a5e8491cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6993d0-7672-4d9e-97f4-7b90db6e8bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3e6f4-ea55-48a8-8063-2a3388f3d4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926bb909-8718-4dc7-a0a4-0d5803eb4994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05f8074-21da-45d8-98f8-640ff52a211f",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is the null hypothesis, and how does it differ from the alternative hypothesis\n",
    "The null hypothesis represents no observed effect, while the alternative hypothesis reflects some observed effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9466737-cb16-4dc2-8748-86aa400c45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is the significance level in hypothesis testing, and why is it important\n",
    "Level of significance: It refers to the degree of significance in which we accept or reject the null hypothesis. 100% accuracy is not possible for accepting a hypothesis so we select a level of significance. This is normally denoted with \n",
    "α\n",
    "αand generally it is 0.05 or 5% which means your output should be 95% confident to give a similar kind of result in each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2511ac-cded-460f-bfd8-f63ed994376e",
   "metadata": {},
   "outputs": [],
   "source": [
    " What does a P-value represent in hypothesis testing\n",
    "When analyzing data the p-value tells you the likelihood of seeing your result if the null hypothesis is true. If your P-value is less than the chosen significance level then you reject the null hypothesis otherwise accept it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4fbdb-5415-4f0a-95ce-49aa3d7635cb",
   "metadata": {},
   "outputs": [],
   "source": [
    " How do you interpret the P-value in hypothesis testing\n",
    "Compare the critical-value with t-statistic. If the t-statistic is larger than the critical value, it provides evidence to reject the null hypothesis, and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4eb983-43bc-46e3-b7a6-e4f45fbd141b",
   "metadata": {},
   "outputs": [],
   "source": [
    " What are Type 1 and Type 2 errors in hypothesis testing\n",
    "Type I and Type II Errors are central for hypothesis testing in general, which subsequently impacts various aspects of science including but not limited to statistical analysis. False discovery refers to a Type I error where a true Null Hypothesis is incorrectly rejected. On the other end of the spectrum, Type II errors occur when a true null hypothesis fails to get rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9f8e5-2857-4a96-bc27-54f3741f2bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is the difference between a one-tailed and a two-tailed test in hypothesis testing\n",
    "One-Tailed Test\n",
    "A one-tailed test is based on a uni-directional hypothesis where the area of rejection is on only one side of the sampling distribution. \n",
    "It determines whether a particular population parameter is larger or smaller than the predefined parameter. \n",
    "It uses one single critical value to test the data.\n",
    "\n",
    "Two-Tailed Test\n",
    "A two-tailed test is also called a nondirectional hypothesis.\n",
    "For checking whether the sample is greater or less than a range of values, we use the two-tailed. It is used for null hypothesis testing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45c24c-efbb-42d8-b942-7a8495bb89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is the Z-test, and when is it used in hypothesis testing\n",
    "A Z-test is a type of hypothesis test that compares the sample’s average to the population’s average and \n",
    "calculates the Z-score and tells us how much the sample average is different from the population average by looking at how much the data normally varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86d935-e34e-4f09-8b71-19bed2e20eee",
   "metadata": {},
   "outputs": [],
   "source": [
    " How do you calculate the Z-score, and what does it represent in hypothesis testing\n",
    " a Z test when you need to compare group means. Use the 1-sample analysis to determine whether a population mean is different from a hypothesized value.\n",
    "Or use the 2-sample version to determine whether two population means differ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee41763-546f-44be-bf0d-fa8f555af3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is the T-distribution, and when should it be used instead of the normal distribution\n",
    "You must use the t-distribution table when working problems when the population standard deviation (σ) is not known and the sample size is small (n<30). If σ is not known, then using t-distribution is correct. If σ is known, then using the normal distribution is correct. If σ known, then use normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3460a31-fcbe-4131-b5d4-2cb6dd222fed",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is the difference between a Z-test and a T-test\n",
    "T-Test\n",
    "Compare means of small samples (n < 30)\n",
    "Normally distributed data, approximate normality\n",
    "T-distribution\n",
    "Relatively more complex\n",
    "Z-Test\n",
    "Compare means of large samples (n ≥ 30)\n",
    "Normally distributed data, known population standard deviation\n",
    "Standard normal distribution (Z-distribution)\n",
    "Relatively simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f00f9f-ba20-4ffd-bf32-92b57e345392",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is the T-test, and how is it used in hypothesis testing\n",
    "-Test is a method used in statistics to determine if there is a significant difference between the means of two groups and how they are related.\n",
    "In T-Test statistics, the sample data is a subset of the two groups that we use to draw conclusions about the groups as a whole. \n",
    "t = (x̄ – μ) /(σ / √n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f336a5e-2c24-4fcf-aa56-5ded75350b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " What is the relationship between Z-test and T-test in hypothesis testing\n",
    "Z-test is a statistical test used to determine whether there is a significant difference between \n",
    "sample and population means or between the means of two samples.\n",
    "T-test is a statistical test used to determine whether there is a significant difference between the means of two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883009f3-91c6-4fac-97ac-1ef2227488c1",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is a confidence interval, and how is it used to interpret statistical results\n",
    "Confidence Interval (CI) is a range of values that estimates where the true population value is likely to fall.\n",
    "Instead of just saying The average height of students is 165 cm a confidence interval allow us to say We are 95% confident that the true average height is between 160 cm and 170 cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d882007-e200-482d-9e4f-0e0ddb7f1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is the margin of error, and how does it affect the confidence interval\n",
    "n statistics, both margin of error and confidence interval are crucial concepts used to estimate the value of a population parameter with a certain level of confidence. However, they serve different purposes and are calculated differently.\n",
    "\n",
    "Confidence Interval\n",
    "\n",
    "A confidence interval is a range of values, derived from a sample, that is likely to contain the value of an unknown population parameter. It is expressed as:\n",
    "\n",
    "Confidence Interval = [lower bound, upper bound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba8290-f7a6-47cb-b9d5-dc362705d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    " How is Bayes' Theorem used in statistics, and what is its significance\n",
    "Bayes’ Theorem is a mathematical formula that helps determine the conditional probability of an event based on prior knowledge and new evidence.\n",
    "\n",
    "It adjusts probabilities when new information comes in and helps make better decisions in uncertain situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d5b21-c74d-488a-9cec-18c5f99340b8",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is the Chi-square distribution, and when is it used\n",
    "Chi-square (Χ 2) distributions are a family of continuous probability distributions. \n",
    "They’re widely used in hypothesis tests, including the chi-square goodness of fit test and the chi-square test of independence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842bb632-a9ca-4312-8481-f7f6383e2d74",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is the Chi-square goodness of fit test, and how is it applied\n",
    "A chi-square goodness of fit test is a statistical hypothesis test used to determine whether a categorical variable follows a hypothesized distribution.\n",
    "It compares the observed frequency of each category with the expected frequency based on the distribution.\n",
    "It allows you to test whether the sample data is representative of the full population or whether the frequency distribution is significantly different from your expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4409f2-b5f7-4259-9584-8bba9035c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is the F-distribution, and when is it used in hypothesis testing\n",
    "The F-distribution is a continuous probability distribution that arises frequently in the context of statistical inference, \n",
    "particularly in the analysis of variance (ANOVA) and regression analysis. It is defined by two parameters, known as degrees of freedom, which correspond to the numerator and denominator of the F-statistic.\n",
    "The F-distribution is positively skewed and approaches a normal distribution as the degrees of freedom increase, making it essential for hypothesis testing in various statistical applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc62100-e2d2-4aff-9ccc-d7fe041c119f",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is an ANOVA test, and what are its assumptions\n",
    "Analysis of Variance, or ANOVA, is a statistical method used to compare the means of three or more groups to determine if there are any statistically significant differences among them. \n",
    "ANOVA assesses the variability within and between groups to help researchers understand if the observed differences are due to chance or indicate true effects. \n",
    "This method is widely used across various fields, such as biology, psychology, business, and social sciences.\n",
    "In this guide, we’ll cover the basics of ANOVA, \n",
    "including its formulas, types, and practical examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747eb8b-3bb8-4540-ad01-585e5708d047",
   "metadata": {},
   "outputs": [],
   "source": [
    " What are the different types of ANOVA tests\n",
    "One-way ANOVA: Compares levels of a single factor based on a single continuous response variable.\n",
    "Two-way ANOVA: Involves two independent variables.\n",
    "Repeated Measures ANOVA: Used when measurements are taken on the same subjects at multiple time points.\n",
    "Mixed Design ANOVA: Combines between-subjects and within-subjects factors.\n",
    "Multivariate Analysis of Variance (MANOVA): Used when there are multiple dependent variables.\n",
    "Analysis of Covariance (ANCOVA): Combines ANOVA with linear regression.\n",
    "Nested ANOVA: Involves nested or hierarchical factors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c9396-8c8f-40d3-a41e-559a3f078ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is the F-test, and how does it relate to hypothesis testing?\n",
    "F test is a statistical test that is used in hypothesis testing that determines whether the variances of two samples are equal or not.\n",
    "The article will provide detailed information on f test, f statistic, its calculation, critical value and how to use it to test hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4014b-6e82-43cc-8b88-620ecdb3d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    " Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and \n",
    "interpret the results\n",
    "Sure! Here's a Python program to perform a z-test for comparing a sample mean to a known population mean. This program will also interpret the results for you.\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def z_test(sample_data, population_mean, population_std_dev):\n",
    "    # Calculate sample mean\n",
    "    sample_mean = np.mean(sample_data)\n",
    "    \n",
    "    # Calculate sample size\n",
    "    sample_size = len(sample_data)\n",
    "    \n",
    "    # Calculate standard error\n",
    "    standard_error = population_std_dev / np.sqrt(sample_size)\n",
    "    \n",
    "    # Calculate z-score\n",
    "    z_score = (sample_mean - population_mean) / standard_error\n",
    "    \n",
    "    # Calculate p-value\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "    \n",
    "    return z_score, p_value\n",
    "\n",
    "# Sample data\n",
    "sample_data = [12, 15, 14, 10, 13, 14, 15, 16, 14, 13]\n",
    "\n",
    "# Known population parameters\n",
    "population_mean = 13\n",
    "population_std_dev = 2\n",
    "\n",
    "# Perform z-test\n",
    "z_score, p_value = z_test(sample_data, population_mean, population_std_dev)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # significance level\n",
    "\n",
    "print(f\"Z-Score: {z_score}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0007d-7540-4404-8cff-d18e412ce306",
   "metadata": {},
   "outputs": [],
   "source": [
    " Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python\n",
    "Sure! Here's a concise example of how you can simulate random data, perform hypothesis testing, and calculate the corresponding p-value using Python. We'll use the scipy library for statistical functions.\n",
    "\n",
    "Example: Two-Sample t-Test\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Simulate random data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "data1 = np.random.normal(loc=50, scale=10, size=100)  # Sample 1: mean=50, std=10, n=100\n",
    "data2 = np.random.normal(loc=55, scale=10, size=100)  # Sample 2: mean=55, std=10, n=100\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(data1, data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750be9b2-c056-4111-8136-e5c4ba0ae919",
   "metadata": {},
   "outputs": [],
   "source": [
    " Implement a one-sample Z-test using Python to compare the sample mean with the population mean\n",
    "Certainly! Below is a Python implementation of a one-sample z-test to compare the sample mean with the population mean. This test is used to determine if there is a significant difference between the sample mean and the population mean when the population standard deviation is known.\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def one_sample_z_test(sample_data, population_mean, population_std):\n",
    "    # Calculate the sample mean\n",
    "    sample_mean = np.mean(sample_data)\n",
    "    \n",
    "    # Calculate the sample size\n",
    "    n = len(sample_data)\n",
    "    \n",
    "    # Calculate the standard error of the mean\n",
    "    standard_error = population_std / np.sqrt(n)\n",
    "    \n",
    "    # Calculate the z-score\n",
    "    z_score = (sample_mean - population_mean) / standard_error\n",
    "    \n",
    "    # Calculate the p-value\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "    \n",
    "    return z_score, p_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c5267-21b7-4b12-8668-9b134fbf4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    " Perform a two-tailed Z-test using Python and visualize the decision region on a plot\n",
    "Certainly! Performing a two-tailed Z-test and visualizing the decision region can be quite insightful. Below is a Python script that demonstrates how to do this:\n",
    "\n",
    "Step 1: Perform the Two-Tailed Z-Test\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data\n",
    "sample_mean = 105\n",
    "population_mean = 100\n",
    "population_std = 15\n",
    "sample_size = 30\n",
    "\n",
    "# Calculate the Z-score\n",
    "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
    "\n",
    "# Calculate the p-value for a two-tailed test\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "print(f\"Z-score: {z_score}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "Step 2: Visualize the Decision Region\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Critical Z-values for a two-tailed test\n",
    "z_critical = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "# Plot the standard normal distribution\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "y = stats.norm.pdf(x)\n",
    "\n",
    "plt.plot(x, y, label='Standard Normal Distribution')\n",
    "\n",
    "# Shade the rejection regions\n",
    "plt.fill_between(x, y, where=(x <= -z_critical) | (x >= z_critical), color='red', alpha=0.5, label='Rejection Region')\n",
    "\n",
    "# Plot the Z-score\n",
    "plt.axvline(z_score, color='blue', linestyle='--', label=f'Z-score = {z_score:.2f}')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Z')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Two-Tailed Z-Test Decision Region')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de739dcb-92c2-4cca-92d2-e011e1fc2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    " Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9f476-0040-4ecd-9a2c-49aeae972af5",
   "metadata": {},
   "outputs": [],
   "source": [
    " Write a Python program to perform an independent T-test and interpret the results\n",
    "Certainly! Here's a Python program to perform an independent t-test using the scipy library, along with a brief interpretation of the results.\n",
    "\n",
    "Python Program\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data\n",
    "group1 = [23, 21, 18, 30, 25, 22, 19, 24, 20, 26]\n",
    "group2 = [28, 32, 30, 35, 33, 31, 29, 34, 27, 36]\n",
    "\n",
    "# Perform independent t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2)\n",
    "\n",
    "# Print the results\n",
    "print(f\"T-statistic: {t_stat:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The difference between the two groups is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference between the two groups is not statistically significant.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba19cbd-49a3-45bf-b93c-2412ea8b6935",
   "metadata": {},
   "outputs": [],
   "source": [
    " Perform a paired sample T-test using Python and visualize the comparison results\n",
    "Sure! Performing a paired sample t-test in Python and visualizing the results can be done using libraries like scipy for statistical tests and matplotlib or seaborn for visualization. Here's a step-by-step guide:\n",
    "\n",
    "Step 1: Import Necessary Libraries\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "Step 2: Create Sample Data\n",
    "\n",
    "Let's assume you have two sets of paired data, data1 and data2.\n",
    "\n",
    "# Example data\n",
    "data1 = np.array([23, 21, 18, 30, 28, 35, 40, 50, 45, 38])\n",
    "data2 = np.array([25, 22, 20, 32, 30, 36, 42, 48, 44, 39])\n",
    "\n",
    "Step 3: Perform Paired Sample t-Test\n",
    "t_stat, p_value = stats.ttest_rel(data1, data2)\n",
    "print(f'T-statistic: {t_stat}, P-value: {p_value}')\n",
    "\n",
    "Step 4: Visualize the Comparison\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a DataFrame for better visualization with seaborn\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Data1': data1, 'Data2': data2})\n",
    "\n",
    "# Plotting the data\n",
    "sns.boxplot(data=df)\n",
    "sns.swarmplot(data=df, color=\".25\")\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Paired Sample Comparison')\n",
    "plt.ylabel('Values')\n",
    "plt.xlabel('Groups')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc01ed-09a2-4a68-b324-136396ed6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    " Simulate data and perform both Z-test and T-test, then compare the results using Python\n",
    "Sure! Let's simulate some data and perform both a z-test and a t-test using Python. We'll then compare the results. Here's a step-by-step guide:\n",
    "\n",
    "Step 1: Simulate Data\n",
    "\n",
    "We'll generate two sets of data from normal distributions.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate two sets of data\n",
    "data1 = np.random.normal(loc=50, scale=10, size=100)\n",
    "data2 = np.random.normal(loc=52, scale=10, size=100)\n",
    "\n",
    "Step 2: Perform Z-Test\n",
    "\n",
    "For the z-test, we'll assume we know the population standard deviations.\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Population standard deviations (assumed known)\n",
    "sigma1 = 10\n",
    "sigma2 = 10\n",
    "\n",
    "# Calculate the z-score\n",
    "z_score = (np.mean(data1) - np.mean(data2)) / np.sqrt((sigma1**2 / len(data1)) + (sigma2**2 / len(data2)))\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value_z = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "print(f\"Z-Test: z-score = {z_score:.2f}, p-value = {p_value_z:.4f}\")\n",
    "\n",
    "Step 3: Perform T-Test\n",
    "\n",
    "For the t-test, we'll use the sample standard deviations.\n",
    "\n",
    "# Calculate the t-score and p-value\n",
    "t_score, p_value_t = stats.ttest_ind(data1, data2)\n",
    "\n",
    "print(f\"T-Test: t-score = {t_score:.2f}, p-value = {p_value_t:.4f}\")\n",
    "\n",
    "Step 4: Compare Results\n",
    "\n",
    "Now, let's compare the results of the z-test and t-test.\n",
    "\n",
    "print(f\"Comparison of Z-Test and T-Test Results:\")\n",
    "print(f\"Z-Test: z-score = {z_score:.2f}, p-value = {p_value_z:.4f}\")\n",
    "print(f\"T-Test: t-score = {t_score:.2f}, p-value = {p_value_t:.4f}\")\n",
    "\n",
    "Full Code\n",
    "\n",
    "Here is the complete code for your convenience:\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate two sets of data\n",
    "data1 = np.random.normal(loc=50, scale=10, size=100)\n",
    "data2 = np.random.normal(loc=52, scale=10, size=100)\n",
    "\n",
    "# Population standard deviations (assumed known)\n",
    "sigma1 = 10\n",
    "sigma2 = 10\n",
    "\n",
    "# Calculate the z-score\n",
    "z_score = (np.mean(data1) - np.mean(data2)) / np.sqrt((sigma1**2 / len(data1)) + (sigma2**2 / len(data2)))\n",
    "\n",
    "# Calculate the p-value for z-test\n",
    "p_value_z = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "# Calculate the t-score and p-value for t-test\n",
    "t_score, p_value_t = stats.ttest_ind(data1, data2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d4766-648a-4b74-ae3a-3d428f079349",
   "metadata": {},
   "outputs": [],
   "source": [
    " Write a Python function to calculate the confidence interval for a sample mean and explain its significance.\n",
    "Certainly! Below is a Python function to calculate the confidence interval for a sample mean, along with an explanation of its significance.\n",
    "\n",
    "Python Function\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculate the confidence interval for a sample mean.\n",
    "\n",
    "    Parameters:\n",
    "    data (list or array): The sample data.\n",
    "    confidence (float): The confidence level (default is 0.95).\n",
    "\n",
    "    Returns:\n",
    "    tuple: Lower and upper bounds of the confidence interval.\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    mean = np.mean(data)\n",
    "    sem = stats.sem(data)  # Standard error of the mean\n",
    "    margin_of_error = sem * stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    \n",
    "    return mean - margin_of_error, mean + margin_of_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d702bf-348f-4e32-b22c-edfa215d2ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write a Python program to calculate the margin of error for a given confidence level using sample data\n",
    "Certainly! Below is a Python program that calculates the margin of error for a given confidence level using sample data. This program uses the scipy library to find the critical value (z-score) for the specified confidence level.\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def calculate_margin_of_error(data, confidence_level):\n",
    "    # Convert confidence level to a proportion (e.g., 95% -> 0.95)\n",
    "    confidence_proportion = confidence_level / 100.0\n",
    "    \n",
    "    # Calculate the sample mean and standard deviation\n",
    "    sample_mean = np.mean(data)\n",
    "    sample_std_dev = np.std(data, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    \n",
    "    # Calculate the sample size\n",
    "    sample_size = len(data)\n",
    "    \n",
    "    # Calculate the standard error\n",
    "    standard_error = sample_std_dev / np.sqrt(sample_size)\n",
    "    \n",
    "    # Find the critical value (z-score) for the given confidence level\n",
    "    z_score = stats.norm.ppf((1 + confidence_proportion) / 2)\n",
    "    \n",
    "    # Calculate the margin of error\n",
    "    margin_of_error = z_score * standard_error\n",
    "    \n",
    "    return margin_of_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54d1aa-cc10-4cad-a155-2a6042da8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "11) Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process\n",
    "Sure! Let's implement a Bayesian inference method using Bayes' Theorem in Python. I'll also explain the process step-by-step.\n",
    "\n",
    "Bayes' Theorem\n",
    "\n",
    "Bayes' Theorem is a way of finding a probability when we know certain other probabilities. The formula is:\n",
    "\n",
    "$$ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} $$\n",
    "\n",
    "Where:\n",
    "\n",
    "( P(A|B) ) is the posterior probability: the probability of hypothesis ( A ) given the data ( B ).\n",
    "( P(B|A) ) is the likelihood: the probability of data ( B ) given that hypothesis ( A ) is true.\n",
    "( P(A) ) is the prior probability: the initial probability of hypothesis ( A ).\n",
    "( P(B) ) is the marginal likelihood: the total probability of data ( B ).\n",
    "Example Scenario\n",
    "\n",
    "Let's consider a medical test for a disease:\n",
    "\n",
    "The probability of having the disease (prior), ( P(D) ), is 0.01.\n",
    "The probability of testing positive given the disease (likelihood), ( P(T|D) ), is 0.99.\n",
    "The probability of testing positive without the disease (false positive rate), ( P(T|\\neg D) ), is 0.05.\n",
    "\n",
    "We want to find the probability of having the disease given a positive test result (posterior), ( P(D|T) ).\n",
    "\n",
    "Implementation in Python\n",
    "def bayesian_inference(prior, likelihood, false_positive_rate):\n",
    "    # Calculate the marginal likelihood\n",
    "    marginal_likelihood = (likelihood * prior) + (false_positive_rate * (1 - prior))\n",
    "    \n",
    "    # Calculate the posterior probability\n",
    "    posterior = (likelihood * prior) / marginal_likelihood\n",
    "    \n",
    "    return posterior\n",
    "\n",
    "# Given probabilities\n",
    "prior = 0.01  # P(D)\n",
    "likelihood = 0.99  # P(T|D)\n",
    "false_positive_rate = 0.05  # P(T|¬D)\n",
    "\n",
    "# Calculate the posterior probability\n",
    "posterior = bayesian_inference(prior, likelihood, false_positive_rate)\n",
    "\n",
    "print(f\"The probability of having the disease given a positive test result is {posterior:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08d3d49-0b9c-44ca-8a1d-ffae5b6b7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    " Perform a Chi-square test for independence between two categorical variables in Python\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# defining the table\n",
    "data = [[207, 282, 241], [234, 242, 232]]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "\n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"p value is \" + str(p))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4426d-a6aa-4dec-919f-f77009b18baa",
   "metadata": {},
   "outputs": [],
   "source": [
    " Write a Python program to calculate the expected frequencies for a Chi-square test based on observed \n",
    "data\n",
    "import numpy as np\n",
    "\n",
    "def calculate_expected_frequencies(observed):\n",
    "    \"\"\"\n",
    "    Calculate the expected frequencies for a chi-square test.\n",
    "    \n",
    "    Parameters:\n",
    "    observed (2D list or numpy array): The observed frequencies in a contingency table.\n",
    "    \n",
    "    Returns:\n",
    "    numpy array: The expected frequencies.\n",
    "    \"\"\"\n",
    "    observed = np.array(observed)\n",
    "    row_totals = observed.sum(axis=1)\n",
    "    col_totals = observed.sum(axis=0)\n",
    "    grand_total = observed.sum()\n",
    "    \n",
    "    expected = np.outer(row_totals, col_totals) / grand_total\n",
    "    return expected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa099f5-b216-4667-b0c7-357fb33a5903",
   "metadata": {},
   "outputs": [],
   "source": [
    " Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution\n",
    "\n",
    "Import Libraries:\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "\n",
    "Define Observed and Expected Data: Let's assume you have observed data and an expected distribution. For example:\n",
    "\n",
    "observed = np.array([18, 22, 20, 15, 25])\n",
    "expected = np.array([20, 20, 20, 20, 20])\n",
    "\n",
    "\n",
    "Perform the Chi-Square Goodness of Fit Test:\n",
    "\n",
    "chi2_stat, p_val = chisquare(f_obs=observed, f_exp=expected)\n",
    "\n",
    "\n",
    "Interpret the Results:\n",
    "\n",
    "print(f\"Chi-Square Statistic: {chi2_stat}\")\n",
    "print(f\"P-Value: {p_val}\")\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(\"The observed data significantly differs from the expected distribution (reject H0).\")\n",
    "else:\n",
    "    print(\"The observed data does not significantly differ from the expected distribution (fail to reject H0).\")\n",
    "\n",
    "Complete Code Example\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# Observed and expected data\n",
    "observed = np.array([18, 22, 20, 15, 25])\n",
    "expected = np.array([20, 20, 20, 20, 20])\n",
    "\n",
    "# Perform Chi-Square Goodness of Fit Test\n",
    "chi2_stat, p_val = chisquare(f_obs=observed, f_exp=expected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78491af0-2f43-4640-89c7-1fb531638891",
   "metadata": {},
   "outputs": [],
   "source": [
    " Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Set the degrees of freedom\n",
    "df = 5\n",
    "\n",
    "# Generate random samples from a Chi-Square distribution\n",
    "samples = np.random.chisquare(df, 1000)\n",
    "\n",
    "# Plot the histogram of the samples\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(samples, bins=30, kde=True, color='skyblue', stat='density')\n",
    "\n",
    "# Plot the theoretical Chi-Square distribution\n",
    "x = np.linspace(0, max(samples), 1000)\n",
    "plt.plot(x, chi2.pdf(x, df), 'r-', lw=2, label=f'Chi-Square PDF (df={df})')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Chi-Square Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166507c8-df6a-435b-8c72-8f846d817d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    " Implement an F-test using Python to compare the variances of two random samples\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "# Generate two random samples\n",
    "np.random.seed(0)  # For reproducibility\n",
    "sample1 = np.random.normal(loc=0, scale=1, size=100)\n",
    "sample2 = np.random.normal(loc=0, scale=1.5, size=100)\n",
    "\n",
    "# Calculate the variances of the samples\n",
    "var1 = np.var(sample1, ddof=1)\n",
    "var2 = np.var(sample2, ddof=1)\n",
    "\n",
    "# Calculate the F-statistic\n",
    "F = var1 / var2 if var1 > var2 else var2 / var1\n",
    "\n",
    "# Degrees of freedom\n",
    "df1 = len(sample1) - 1\n",
    "df2 = len(sample2) - 1\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = 1 - f.cdf(F, df1, df2)\n",
    "\n",
    "# Two-tailed test adjustment\n",
    "p_value *= 2\n",
    "\n",
    "print(f\"F-statistic: {F}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The variances are significantly different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The variances are not significantly different.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d775768-b89d-40b4-ab30-1dc552dd934e",
   "metadata": {},
   "outputs": [],
   "source": [
    " Write a Python program to perform an ANOVA test to compare means between multiple groups and \n",
    "interpret the results\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data: three groups with different means\n",
    "group1 = [23, 20, 22, 21, 24]\n",
    "group2 = [30, 32, 29, 31, 33]\n",
    "group3 = [40, 42, 39, 41, 43]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
    "\n",
    "# Print the results\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The differences between the group means are statistically significant (reject the null hypothesis).\")\n",
    "else:\n",
    "    print(\"The differences between the group means are not statistically significant (fail to reject the null hypothesis).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dec22c-2e75-4a3f-83a2-6c315e578dda",
   "metadata": {},
   "outputs": [],
   "source": [
    " Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results\n",
    "\n",
    "Step 1: Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "Step 2: Create Sample Data\n",
    "\n",
    "Let's create some sample data for three groups.\n",
    "\n",
    "# Sample data\n",
    "np.random.seed(42)\n",
    "group1 = np.random.normal(20, 5, 30)\n",
    "group2 = np.random.normal(22, 5, 30)\n",
    "group3 = np.random.normal(19, 5, 30)\n",
    "\n",
    "# Combine into a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Group': ['Group1']*30 + ['Group2']*30 + ['Group3']*30,\n",
    "    'Value': np.concatenate([group1, group2, group3])\n",
    "})\n",
    "\n",
    "Step 3: Perform One-Way ANOVA\n",
    "# Perform one-way ANOVA\n",
    "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
    "\n",
    "print(f\"F-statistic: {f_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "Step 4: Plot the Results\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Group', y='Value', data=data)\n",
    "plt.title('Boxplot of Different Groups')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "Full Code\n",
    "\n",
    "Here's the complete code for your convenience:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample data\n",
    "np.random.seed(42)\n",
    "group1 = np.random.normal(20, 5, 30)\n",
    "group2 = np.random.normal(22, 5, 30)\n",
    "group3 = np.random.normal(19, 5, 30)\n",
    "\n",
    "# Combine into a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Group': ['Group1']*30 + ['Group2']*30 + ['Group3']*30,\n",
    "    'Value': np.concatenate([group1, group2, group3])\n",
    "})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
    "\n",
    "print(f\"F-statistic: {f_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Group', y='Value', data=data)\n",
    "plt.title('Boxplot of Different Groups')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924ed4f-271b-4f04-ab7c-e6e2cd29e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    " Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def check_anova_assumptions(data, group_col, value_col):\n",
    "    \"\"\"\n",
    "    Check assumptions for ANOVA: normality, independence, and equal variance.\n",
    "    \n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The dataset containing the groups and values.\n",
    "    group_col (str): The column name for the groups.\n",
    "    value_col (str): The column name for the values.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with the results of the assumption checks.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Normality check using Shapiro-Wilk test\n",
    "    normality_p_values = {}\n",
    "    for group in data[group_col].unique():\n",
    "        group_data = data[data[group_col] == group][value_col]\n",
    "        stat, p_value = stats.shapiro(group_data)\n",
    "        normality_p_values[group] = p_value\n",
    "    results['normality'] = normality_p_values\n",
    "    \n",
    "    # Independence check (visual inspection of residuals)\n",
    "    # Residuals should be randomly scattered around zero\n",
    "    model = ols(f'{value_col} ~ C({group_col})', data=data).fit()\n",
    "    residuals = model.resid\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(range(len(residuals)), residuals)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.title('Residuals Scatter Plot')\n",
    "    plt.xlabel('Observation')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.show()\n",
    "    \n",
    "    # Equal variance check using Levene's test\n",
    "    group_data = [data[data[group_col] == group][value_col] for group in data[group_col].unique()]\n",
    "    stat, p_value = stats.levene(*group_data)\n",
    "    results['equal_variance'] = p_value\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719be7e-7545-44ba-b079-16e0beb166f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the \n",
    "results\n",
    "\n",
    "Step 1: Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Step 2: Create or Load Your Data\n",
    "\n",
    "For demonstration, let's create a sample dataset:\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Factor1': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Factor2': ['X', 'Y', 'Z', 'X', 'Y', 'Z', 'X', 'Y', 'Z'],\n",
    "    'Response': [5, 7, 8, 6, 9, 12, 7, 10, 13]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "Step 3: Perform Two-Way ANOVA\n",
    "# Define the model\n",
    "model = ols('Response ~ C(Factor1) * C(Factor2)', data=df).fit()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "Step 4: Visualize the Results\n",
    "Interaction Plot\n",
    "# Interaction plot\n",
    "sns.pointplot(x='Factor1', y='Response', hue='Factor2', data=df, markers=[\"o\", \"s\", \"D\"], linestyles=[\"-\", \"--\", \"-.\"])\n",
    "plt.title('Interaction Plot')\n",
    "plt.xlabel('Factor1')\n",
    "plt.ylabel('Response')\n",
    "plt.legend(title='Factor2')\n",
    "plt.show()\n",
    "\n",
    "Boxplot for Each Factor\n",
    "# Boxplot for Factor1\n",
    "sns.boxplot(x='Factor1', y='Response', data=df)\n",
    "plt.title('Boxplot of Response by Factor1')\n",
    "plt.xlabel('Factor1')\n",
    "plt.ylabel('Response')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for Factor2\n",
    "sns.boxplot(x='Factor2', y='Response', data=df)\n",
    "plt.title('Boxplot of Response by Factor2')\n",
    "plt.xlabel('Factor2')\n",
    "plt.ylabel('Response')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f74215-7dc7-427d-a3c0-d60fe8b7829f",
   "metadata": {},
   "outputs": [],
   "source": [
    " Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f\n",
    "\n",
    "# Parameters for the F-distribution\n",
    "dof1 = 5  # degrees of freedom for the numerator\n",
    "dof2 = 10  # degrees of freedom for the denominator\n",
    "\n",
    "# Generate x values\n",
    "x = np.linspace(0, 5, 1000)\n",
    "\n",
    "# Calculate the F-distribution probability density function (pdf)\n",
    "y = f.pdf(x, dof1, dof2)\n",
    "\n",
    "# Plot the F-distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y, label=f'F-distribution (dof1={dof1}, dof2={dof2})', color='blue')\n",
    "plt.fill_between(x, y, alpha=0.2, color='blue')\n",
    "plt.title('F-Distribution')\n",
    "plt.xlabel('F-value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843010f0-119e-424c-888e-29b23b194821",
   "metadata": {},
   "outputs": [],
   "source": [
    " Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Group': ['A']*10 + ['B']*10 + ['C']*10,\n",
    "    'Value': np.random.normal(10, 2, 10).tolist() + \n",
    "             np.random.normal(12, 2, 10).tolist() + \n",
    "             np.random.normal(11, 2, 10).tolist()\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "anova_result = stats.f_oneway(df[df['Group'] == 'A']['Value'],\n",
    "                              df[df['Group'] == 'B']['Value'],\n",
    "                              df[df['Group'] == 'C']['Value'])\n",
    "\n",
    "print(f\"ANOVA F-value: {anova_result.statistic}\")\n",
    "print(f\"ANOVA p-value: {anova_result.pvalue}\")\n",
    "\n",
    "# Create a boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Group', y='Value', data=df)\n",
    "plt.title('Boxplot of Group Values')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f23de-4b6d-4dd8-9075-d052b123caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    " Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means\n",
    "# Set-up Python libraries - you need to run this but you don't need to change it\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='white')\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings \n",
    "warnings.simplefilter('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a18331-2710-4d16-afaf-e856d9b4ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    " Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f7167-f467-43f2-b9fb-2d64d74955ea",
   "metadata": {},
   "outputs": [],
   "source": [
    " Write a Python script to perform a Z-test for comparing proportions between two datasets or groups\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def z_test_proportions(success_a, size_a, success_b, size_b):\n",
    "    # Calculate the proportions\n",
    "    p1 = success_a / size_a\n",
    "    p2 = success_b / size_b\n",
    "    \n",
    "    # Calculate the pooled proportion\n",
    "    p_pool = (success_a + success_b) / (size_a + size_b)\n",
    "    \n",
    "    # Calculate the standard error\n",
    "    se = np.sqrt(p_pool * (1 - p_pool) * (1/size_a + 1/size_b))\n",
    "    \n",
    "    # Calculate the Z-score\n",
    "    z_score = (p1 - p2) / se\n",
    "    \n",
    "    # Calculate the p-value\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "    \n",
    "    return z_score, p_value\n",
    "\n",
    "# Example usage\n",
    "success_a = 50  # Number of successes in group A\n",
    "size_a = 200    # Size of group A\n",
    "success_b = 30  # Number of successes in group B\n",
    "size_b = 150    # Size of group B\n",
    "\n",
    "z_score, p_value = z_test_proportions(success_a, size_a, success_b, size_b)\n",
    "\n",
    "print(f\"Z-score: {z_score}\")\n",
    "print(f\"P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ee5eb-2f6c-4555-b8e3-4de35bdd73fa",
   "metadata": {},
   "outputs": [],
   "source": [
    " Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64dabfa-46fd-4e0a-8f9b-b4ab378dee72",
   "metadata": {},
   "outputs": [],
   "source": [
    " Perform a Chi-square test for goodness of fit with simulated data and analyze the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c714c-6e71-48eb-b1cf-e237ec970d06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
